{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184bf7bc-ecb8-4273-972e-e36b1c81df06",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train_ssl = create_dataset_train_ssl(SwaVModel)\n",
    "data_loader, dataloader_train_kNN, dataloader_test = get_data_loaders(\n",
    "    batch_size=batch_size, dataset_train_ssl=dataset_train_ssl\n",
    ")\n",
    "model = SwaVModel(dataloader_train_kNN, classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc89767-a65c-4b80-8703-74ec40e76596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.stats import entropy\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from itertools import combinations\n",
    "from scipy.special import comb\n",
    "# Assuming you have a 'model' and a 'data_loader' already defined\n",
    "\n",
    "def generate_embeddings(model, data_loader):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            views, _, _ = batch\n",
    "            zs = [model(view) for view in views]  # Process each view\n",
    "            zs = torch.stack(zs)  # Stack embeddings\n",
    "            all_embeddings.append(zs.cpu().numpy())\n",
    "    return np.concatenate(all_embeddings, axis=1)  # Concatenate along the sample dimension\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate the entropy using Kernel Density Estimation\n",
    "def kde_entropy(embedding, bandwidth=0.1):\n",
    "    if embedding.ndim == 1:\n",
    "        embedding = embedding.reshape(-1, 1)  # Reshaping for KDE if 1D\n",
    "\n",
    "    # Standardizing the data\n",
    "    embedding = (embedding - np.mean(embedding, axis=0)) / np.std(embedding, axis=0)\n",
    "\n",
    "    kde = KernelDensity(kernel='gaussian', bandwidth=bandwidth)\n",
    "    kde.fit(embedding)\n",
    "    log_dens = kde.score_samples(embedding)\n",
    "\n",
    "    # Ensure that log densities are not positive\n",
    "    log_dens = np.minimum(log_dens, 0)\n",
    "\n",
    "    return -np.mean(log_dens)\n",
    "\n",
    "\n",
    "def calculate_joint_entropy(embeddings, bandwidth=0.1):\n",
    "    # Reshape and stack all embeddings for joint entropy calculation\n",
    "    stacked_embeddings = np.vstack([e.reshape(-1, 1) for e in embeddings])\n",
    "    return kde_entropy(stacked_embeddings, bandwidth)\n",
    "\n",
    "def calculate_mutual_information(embeddings, bandwidth=0.1):\n",
    "    mi = 0\n",
    "    n_views = len(embeddings)\n",
    "    for combo in combinations(range(n_views), 2):\n",
    "        # Stack the embeddings for the combination\n",
    "        combo_embedding = np.vstack([embeddings[i].reshape(-1, 1) for i in combo])\n",
    "        \n",
    "        # Calculate the joint entropy for the combination\n",
    "        joint_entropy = kde_entropy(combo_embedding, bandwidth)\n",
    "        \n",
    "        # Calculate individual entropies\n",
    "        individual_entropies = sum(kde_entropy(embeddings[i].reshape(-1, 1), bandwidth) for i in combo)\n",
    "        \n",
    "        mi += individual_entropies - joint_entropy\n",
    "    return mi / comb(n_views, 2)\n",
    "\n",
    "\n",
    "\n",
    "from scipy.special import comb\n",
    "from tqdm import tqdm\n",
    "# Initialize an array to store the results\n",
    "results = []\n",
    "embeddings = generate_embeddings(model, data_loader)\n",
    "\n",
    "for sample_idx in tqdm(range(400)): #embeddings.shape[1]\n",
    "    # Example usage for the 18th sample\n",
    "    sample_embeddings = embeddings[:, sample_idx, :]\n",
    "\n",
    "    # Calculate mean embedding for the current sample\n",
    "    mean_embedding = np.mean(sample_embeddings, axis=0)\n",
    "\n",
    "    # Calculate entropy of the mean embedding\n",
    "    mean_entropy = kde_entropy(mean_embedding.reshape(-1, 1))\n",
    "\n",
    "    # Reshape embeddings for each view for joint entropy and MI calculations\n",
    "    reshaped_embeddings = [sample_embeddings[i, :].reshape(-1, 1) for i in range(sample_embeddings.shape[0])]\n",
    "\n",
    "    # Calculate joint entropy of all embeddings for the current sample\n",
    "    joint_entropy = calculate_joint_entropy(reshaped_embeddings)\n",
    "\n",
    "    # Calculate mutual information for the current sample\n",
    "    mi = calculate_mutual_information(reshaped_embeddings)\n",
    "\n",
    "    # Append the results for this sample\n",
    "    results.append([mi, mean_entropy, joint_entropy])\n",
    "\n",
    "# Convert results to a numpy array\n",
    "results_array = np.array(results)\n",
    "\n",
    "# results_array is of shape (samples, 3) where columns are MI, Mean Entropy, Joint Entropy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e385c3-38e0-4eca-a89f-424bea5b7785",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Assuming you have the results_array\n",
    "satisfactory_samples = np.sum((results_array[:, 0] <= results_array[:, 1]) & (results_array[:, 1] <= results_array[:, 2]))\n",
    "total_samples = results_array.shape[0]\n",
    "proportion_satisfactory = satisfactory_samples / total_samples\n",
    "\n",
    "# Set the threshold for 'most' of the data\n",
    "threshold = 0.85\n",
    "\n",
    "# Perform a binomial test\n",
    "test_result = stats.binomtest(satisfactory_samples, total_samples, threshold, alternative='greater')\n",
    "\n",
    "# Output the results\n",
    "print(f\"Number of samples satisfying the condition: {satisfactory_samples} out of {total_samples}\")\n",
    "print(f\"Proportion of satisfactory samples: {proportion_satisfactory:.2f}\")\n",
    "print(f\"Binomial test p-value for threshold {threshold}: {test_result.pvalue:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
